#!/bin/bash
# GPU Instance Setup Script for Bucket Brigade PPO Training
# Usage: ./setup_gpu.sh [install_dir]
#
# If run from within bucket-brigade repo, uses current directory
# Otherwise clones to specified directory (default: ~/bucket-brigade)

set -e

echo "ğŸš€ Setting up Bucket Brigade on GPU instance..."

# Determine installation directory
if [ -f "pyproject.toml" ] && grep -q "bucket-brigade" pyproject.toml 2>/dev/null; then
    echo "âœ“ Running from bucket-brigade directory"
    REPO_DIR="$(pwd)"
else
    INSTALL_DIR="${1:-$HOME/bucket-brigade}"
    if [ ! -d "$INSTALL_DIR" ]; then
        echo "ğŸ“¦ Cloning bucket-brigade to $INSTALL_DIR..."
        git clone https://github.com/rjwalters/bucket-brigade.git "$INSTALL_DIR"
    else
        echo "âœ“ Found existing repo at $INSTALL_DIR"
    fi
    REPO_DIR="$INSTALL_DIR"
    cd "$REPO_DIR"
fi

echo "ğŸ“ Working directory: $REPO_DIR"

# Check if we're on a GPU instance
if ! command -v nvidia-smi &> /dev/null; then
    echo "âš ï¸  Warning: nvidia-smi not found. Are you on a GPU instance?"
fi

# Install uv if not present
if ! command -v uv &> /dev/null; then
    echo "ğŸ“¦ Installing uv..."
    curl -LsSf https://astral.sh/uv/install.sh | sh
    export PATH="$HOME/.cargo/bin:$PATH"
fi

# Create Python environment
echo "ğŸ Creating Python environment..."
uv venv
source .venv/bin/activate

# Install dependencies with RL extras (torch, pufferlib, etc.)
echo "ğŸ“š Installing dependencies (this may take a few minutes)..."
uv sync --extra rl

# Build Rust core with PyO3 bindings
echo "ğŸ¦€ Building Rust core..."
cd bucket-brigade-core
VIRTUAL_ENV="$(pwd)/../.venv" \
  PYO3_USE_ABI3_FORWARD_COMPATIBILITY=1 \
  ../.venv/bin/maturin develop --release --features python
cd ..

# Verify installation
echo ""
echo "âœ… Verifying installation..."

# Check CUDA
.venv/bin/python << 'EOF'
import torch
cuda_available = torch.cuda.is_available()
device_count = torch.cuda.device_count()
print(f"ğŸ” CUDA Available: {cuda_available}")
if cuda_available:
    print(f"ğŸ” GPU Count: {device_count}")
    for i in range(device_count):
        print(f"ğŸ” GPU {i}: {torch.cuda.get_device_name(i)}")
else:
    print("âš ï¸  No CUDA devices found - training will use CPU")
EOF

# Check Rust environment
.venv/bin/python << 'EOF'
try:
    from bucket_brigade.envs.puffer_env_rust import make_rust_env
    import bucket_brigade_core as core

    print(f"âœ… Rust core imported successfully")
    print(f"âœ… Available scenarios: {len(core.SCENARIOS)}")

    # Test environment creation
    env = make_rust_env('trivial_cooperation', num_opponents=3)
    obs, _ = env.reset()
    print(f"âœ… Environment created successfully (obs shape: {obs.shape})")

except Exception as e:
    print(f"âŒ Error: {e}")
    exit(1)
EOF

echo ""
echo "ğŸ‰ Setup complete!"
echo ""
echo "ğŸ“‹ Next steps:"
echo "  1. Start training:"
echo "     uv run python experiments/marl/train_gpu.py --steps 10000000 --scenario trivial_cooperation"
echo ""
echo "  2. Monitor with TensorBoard (in another terminal):"
echo "     tensorboard --logdir experiments/marl/runs/"
echo ""
echo "  3. Forward TensorBoard port to local machine:"
echo "     ssh -L 6006:localhost:6006 rwalters-sandbox-2"
echo "     Then open: http://localhost:6006"
echo ""
