{
  "name": "sparse_heroics",
  "description": "Sparse Heroics - few workers can make the difference",
  "parameters": {
    "beta": 0.1,
    "kappa": 0.5,
    "A": 100.0,
    "L": 100.0,
    "c": 0.8,
    "rho_ignite": 0.15,
    "N_min": 20,
    "p_spark": 0.02,
    "N_spark": 20,
    "num_agents": 4
  },
  "research_config": {
    "num_heuristic_games": 100,
    "evolution_generations": 200,
    "evolution_population": 100,
    "nash_simulations": 1000,
    "nash_max_iterations": 50
  },
  "story": "Fires spread very slowly (\u03b2=0.1) over long games (20 nights minimum), but high work cost (c=0.8) punishes constant vigilance. The optimal strategy requires identifying when heroic action is needed versus when rest is acceptable. A few well-timed interventions beat continuous effort.",
  "research_questions": [
    "Can agents learn when to rest versus when to work?",
    "How many 'hero' agents are needed to succeed?",
    "Does signaling help coordinate sparse interventions?",
    "What is the optimal work/rest ratio for this scenario?"
  ],
  "research_insights": [
    {
      "question": "Why does Nash equilibrium favor cooperation in this scenario?",
      "finding": "Nash equilibrium selects highly cooperative strategies (100% cooperation rate) achieving 80.7 payoff.",
      "evidence": [
        "Equilibrium type: pure",
        "Strategy classification: Coordinator",
        "Expected payoff: 80.71",
        "Cooperation rate: 100%",
        "Convergence: 1 iterations in 457.1s"
      ],
      "implication": "The incentive structure naturally aligns individual and collective interests, making cooperation individually rational without enforcement."
    },
    {
      "question": "What strategic traits does Nash equilibrium emphasize?",
      "finding": "The equilibrium strongly favors coordination, honesty (all > 0.7) as critical for stability.",
      "evidence": [
        "coordination: 1.00",
        "honesty: 0.90",
        "Archetype: Coordinator (distance: 0.00)"
      ],
      "implication": "These traits are Nash-stable because they form mutually best responses - no agent can improve by unilaterally deviating."
    },
    {
      "question": "How effective was evolutionary optimization?",
      "finding": "Evolution improved from -1.8 to 1.0 payoff over 201 generations (\u0394 2.8).",
      "evidence": [
        "Initial best fitness: -1.75",
        "Final best fitness: 1.00",
        "Total improvement: 2.75",
        "Generations: 201",
        "Converged: False"
      ],
      "implication": "Limited improvement suggests either strong initial random strategies or a complex fitness landscape with many local optima."
    },
    {
      "question": "What does population diversity reveal about the fitness landscape?",
      "finding": "Population reached moderate diversity (0.272), balancing exploration and exploitation.",
      "evidence": [
        "Final diversity: 0.272",
        "Mid-run diversity: 0.296",
        "Best generation: 200"
      ],
      "implication": "Evolution balanced convergence toward good strategies while maintaining variation for continued adaptation."
    },
    {
      "question": "What is the price of anarchy in this scenario?",
      "finding": "Nash equilibrium (80.7) shows moderate efficiency loss of 15.1 points vs optimal (95.8).",
      "evidence": [
        "Nash payoff: 80.71",
        "Optimal payoff: 95.76",
        "Gap: 15.06",
        "Efficiency: 84.3%"
      ],
      "implication": "Partial coordination failure. Some gains possible through cooperation, but individual incentives aren't catastrophically misaligned."
    },
    {
      "question": "Why does evolution fail to reach Nash equilibrium performance?",
      "finding": "Evolution achieves only 59.7 payoff, falling 21.0 points short of Nash equilibrium (80.7).",
      "evidence": [
        "Evolved payoff: 59.70",
        "Nash payoff: 80.71",
        "coordination: 1.00 (Nash) vs 0.20 (Evolved)",
        "altruism: 0.60 (Nash) vs 0.00 (Evolved)"
      ],
      "implication": "Some strategy spaces are too complex for evolution to navigate effectively. The fitness landscape may have local optima that trap evolutionary search."
    },
    {
      "question": "Which agent parameters matter most for success in this scenario?",
      "finding": "The parameter 'work_tendency' shows the largest difference between Nash and optimal strategies, suggesting it's critical for performance.",
      "evidence": [
        "Nash strategy work_tendency: 0.60",
        "Best strategy work_tendency: 0.90",
        "Difference: 0.30",
        "Also important: risk_aversion (\u0394 0.30)",
        "Also important: coordination (\u0394 0.30)"
      ],
      "implication": "Success in this scenario critically depends on optimizing work_tendency. Strategies that neglect this parameter face significant performance penalties."
    }
  ],
  "method_insights": {
    "nash": [
      {
        "question": "Why does Nash equilibrium favor cooperation in this scenario?",
        "finding": "Nash equilibrium selects highly cooperative strategies (100% cooperation rate) achieving 80.7 payoff.",
        "evidence": [
          "Equilibrium type: pure",
          "Strategy classification: Coordinator",
          "Expected payoff: 80.71",
          "Cooperation rate: 100%",
          "Convergence: 1 iterations in 457.1s"
        ],
        "implication": "The incentive structure naturally aligns individual and collective interests, making cooperation individually rational without enforcement."
      },
      {
        "question": "What strategic traits does Nash equilibrium emphasize?",
        "finding": "The equilibrium strongly favors coordination, honesty (all > 0.7) as critical for stability.",
        "evidence": [
          "coordination: 1.00",
          "honesty: 0.90",
          "Archetype: Coordinator (distance: 0.00)"
        ],
        "implication": "These traits are Nash-stable because they form mutually best responses - no agent can improve by unilaterally deviating."
      }
    ],
    "evolution": [
      {
        "question": "How effective was evolutionary optimization?",
        "finding": "Evolution improved from -1.8 to 1.0 payoff over 201 generations (\u0394 2.8).",
        "evidence": [
          "Initial best fitness: -1.75",
          "Final best fitness: 1.00",
          "Total improvement: 2.75",
          "Generations: 201",
          "Converged: False"
        ],
        "implication": "Limited improvement suggests either strong initial random strategies or a complex fitness landscape with many local optima."
      },
      {
        "question": "What does population diversity reveal about the fitness landscape?",
        "finding": "Population reached moderate diversity (0.272), balancing exploration and exploitation.",
        "evidence": [
          "Final diversity: 0.272",
          "Mid-run diversity: 0.296",
          "Best generation: 200"
        ],
        "implication": "Evolution balanced convergence toward good strategies while maintaining variation for continued adaptation."
      }
    ],
    "comparative": [
      {
        "question": "What is the price of anarchy in this scenario?",
        "finding": "Nash equilibrium (80.7) shows moderate efficiency loss of 15.1 points vs optimal (95.8).",
        "evidence": [
          "Nash payoff: 80.71",
          "Optimal payoff: 95.76",
          "Gap: 15.06",
          "Efficiency: 84.3%"
        ],
        "implication": "Partial coordination failure. Some gains possible through cooperation, but individual incentives aren't catastrophically misaligned."
      },
      {
        "question": "Why does evolution fail to reach Nash equilibrium performance?",
        "finding": "Evolution achieves only 59.7 payoff, falling 21.0 points short of Nash equilibrium (80.7).",
        "evidence": [
          "Evolved payoff: 59.70",
          "Nash payoff: 80.71",
          "coordination: 1.00 (Nash) vs 0.20 (Evolved)",
          "altruism: 0.60 (Nash) vs 0.00 (Evolved)"
        ],
        "implication": "Some strategy spaces are too complex for evolution to navigate effectively. The fitness landscape may have local optima that trap evolutionary search."
      },
      {
        "question": "Which agent parameters matter most for success in this scenario?",
        "finding": "The parameter 'work_tendency' shows the largest difference between Nash and optimal strategies, suggesting it's critical for performance.",
        "evidence": [
          "Nash strategy work_tendency: 0.60",
          "Best strategy work_tendency: 0.90",
          "Difference: 0.30",
          "Also important: risk_aversion (\u0394 0.30)",
          "Also important: coordination (\u0394 0.30)"
        ],
        "implication": "Success in this scenario critically depends on optimizing work_tendency. Strategies that neglect this parameter face significant performance penalties."
      }
    ]
  }
}